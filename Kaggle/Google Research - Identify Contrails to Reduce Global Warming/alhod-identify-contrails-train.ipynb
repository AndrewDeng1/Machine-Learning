{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Google Research - Identify Contrails to Reduce Global Warming\nThis is the notebook used to train the UNET model for the \"Google Research - Identify Contrails to Reduce Global Warming\" competition on Kaggle. It ranked 765/954 with dice score 0.59090.\n\nThe dataset used for training was made by kaggler Shashwat Raman.","metadata":{}},{"cell_type":"markdown","source":"# Imports","metadata":{"_uuid":"ccd7a746-d294-4381-b9ca-59160ea53ceb","_cell_guid":"23919d9e-39c8-42f0-9aa7-d1f597eb35f2","trusted":true}},{"cell_type":"code","source":"from pathlib import Path\nimport os\nimport random\nimport math\nfrom collections import defaultdict\nimport cv2\nimport skimage\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport torch\nfrom torch import nn\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom PIL import Image\nfrom tqdm.notebook import tqdm\nfrom transformers import get_cosine_schedule_with_warmup\n\ntorch.__version__","metadata":{"_uuid":"a26aa1c5-1338-464f-8317-9d1b4adf8f61","_cell_guid":"bc35f5f6-eeb2-4ead-8c4c-34cd2f4b4978","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-08-08T14:35:49.263303Z","iopub.execute_input":"2023-08-08T14:35:49.263795Z","iopub.status.idle":"2023-08-08T14:35:49.275360Z","shell.execute_reply.started":"2023-08-08T14:35:49.263739Z","shell.execute_reply":"2023-08-08T14:35:49.274073Z"},"trusted":true},"execution_count":150,"outputs":[{"execution_count":150,"output_type":"execute_result","data":{"text/plain":"'2.0.0'"},"metadata":{}}]},{"cell_type":"code","source":"!pip install segmentation-models-pytorch\nimport segmentation_models_pytorch as smp","metadata":{"_uuid":"02add685-0e90-4efe-94e5-a85c3f77b28b","_cell_guid":"ae7fb136-4370-423b-8664-02c47a4ad2f1","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-08-08T14:35:49.278090Z","iopub.execute_input":"2023-08-08T14:35:49.278522Z","iopub.status.idle":"2023-08-08T14:36:01.796031Z","shell.execute_reply.started":"2023-08-08T14:35:49.278489Z","shell.execute_reply":"2023-08-08T14:36:01.794795Z"},"trusted":true},"execution_count":151,"outputs":[{"name":"stdout","text":"Requirement already satisfied: segmentation-models-pytorch in /opt/conda/lib/python3.10/site-packages (0.3.3)\nRequirement already satisfied: torchvision>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.15.1)\nRequirement already satisfied: pretrainedmodels==0.7.4 in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.7.4)\nRequirement already satisfied: efficientnet-pytorch==0.7.1 in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.7.1)\nRequirement already satisfied: timm==0.9.2 in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.9.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (4.64.1)\nRequirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (9.5.0)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.0.0)\nRequirement already satisfied: munch in /opt/conda/lib/python3.10/site-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch) (4.0.0)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm==0.9.2->segmentation-models-pytorch) (5.4.1)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from timm==0.9.2->segmentation-models-pytorch) (0.15.1)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm==0.9.2->segmentation-models-pytorch) (0.3.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.23.5)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (2.28.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.12.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (2023.6.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (21.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (2023.5.7)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (3.0.9)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.1.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.3.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"# Settings and Paths","metadata":{"_uuid":"8e9988a3-9c75-41b7-8a22-2d5f6294e51c","_cell_guid":"e7b05f36-2714-4f9a-9282-fa9a348b19f3","trusted":true}},{"cell_type":"code","source":"class Config:\n    train=True\n    \n    num_epochs=20\n    \n    num_classes=1\n    batch_size=32\n    seed=42\n    \n    encoder = 'efficientnet-b0'\n    pretrained = True\n    weights = 'imagenet'\n    \n    classes = ['contrail']\n    activation = None\n    in_chans = 3\n    \n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    \n    image_size = 256\n    lr = 3e-4\n    warmup = 0\n    \nclass Paths:\n    train_data_csv = '/kaggle/input/contrails-images-ash-color/train_df.csv'\n    valid_data_csv = '/kaggle/input/contrails-images-ash-color/valid_df.csv'\n    contrails = '/kaggle/input/contrails-images-ash-color/contrails/'","metadata":{"_uuid":"3afa689b-4a0e-4106-83d4-6ed7c8593e6c","_cell_guid":"3db4ae6c-ff54-40d4-8b4d-813de09f2eee","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-08-08T14:36:01.798749Z","iopub.execute_input":"2023-08-08T14:36:01.799525Z","iopub.status.idle":"2023-08-08T14:36:01.808670Z","shell.execute_reply.started":"2023-08-08T14:36:01.799482Z","shell.execute_reply":"2023-08-08T14:36:01.807588Z"},"trusted":true},"execution_count":152,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed=1234):\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    \n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = False\n    torch.backends.cudnn.benchmark = True","metadata":{"_uuid":"43bbcd3a-f208-4680-9a15-0027f9137824","_cell_guid":"921f0ff5-676a-4b95-a259-a0e314c42a02","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-08-08T14:36:01.810471Z","iopub.execute_input":"2023-08-08T14:36:01.811557Z","iopub.status.idle":"2023-08-08T14:36:01.822142Z","shell.execute_reply.started":"2023-08-08T14:36:01.811471Z","shell.execute_reply":"2023-08-08T14:36:01.821173Z"},"trusted":true},"execution_count":153,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{"_uuid":"ec244cee-eb00-4955-87e0-75c51219279a","_cell_guid":"6cff12ac-f029-443d-8453-ecad143d6d95","trusted":true}},{"cell_type":"code","source":"class ContrailsDataset(torch.utils.data.Dataset):\n    def __init__(self, df, train):\n        self.df=df\n        self.train=train\n        \n    def __getitem__(self, index):\n        # Accesses sample and label here (according to index)\n        row = self.df.iloc[index]\n        con_path = row.path\n        con = np.load(str(con_path))\n        \n        # Selects all dimensions before last one. In last dimension, selects all\n        # elements, excluding last one (':-1' means slice to but not include last \n        # one).\n        # All dimensions excluding last element of last one makes up the sample image.\n        img = con[..., :-1]\n        \n        # Selects all dimensions before last one + last element of last dimension\n        # All dimensions + last element of last one make up label\n        label = con[..., -1]\n        \n        img = torch.tensor(img)\n        label = torch.tensor(label)\n        \n        img = img.permute(2, 0, 1)\n    \n        # Returns tuple !!! (sample, label)\n        # Indexing into ContrailDataset returns both sample and label!\n        # img = C x H x W (3 x 256 x 256)\n        # label = H x W (256 x 256)\n        return img.float(), label.float()\n    \n    def __len__(self):\n        return len(self.df)","metadata":{"_uuid":"32b1f8e4-7a4e-445e-ab82-44ccb1e790e5","_cell_guid":"f3d249cd-96ed-488c-ab26-51c7ab3e920b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-08-08T14:36:01.825988Z","iopub.execute_input":"2023-08-08T14:36:01.826316Z","iopub.status.idle":"2023-08-08T14:36:01.837131Z","shell.execute_reply.started":"2023-08-08T14:36:01.826292Z","shell.execute_reply":"2023-08-08T14:36:01.836087Z"},"trusted":true},"execution_count":154,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(Paths.train_data_csv)\nvalid_df = pd.read_csv(Paths.valid_data_csv)\n\ndisplay(train_df)\ndisplay(valid_df)\n\ntrain_df['path'] = Paths.contrails+train_df['record_id'].astype(str)+'.npy'\nvalid_df['path'] = Paths.contrails+valid_df['record_id'].astype(str)+'.npy'\n\ndisplay(train_df)\ndisplay(valid_df)\n\ntrain_ds = ContrailsDataset(train_df, train=True)\nvalid_ds = ContrailsDataset(valid_df, train=False)\n\ndisplay(train_ds[0])\n\ntrain_dl = DataLoader(train_ds, batch_size=Config.batch_size, shuffle=True, num_workers=2)\nvalid_dl = DataLoader(valid_ds, batch_size=Config.batch_size, shuffle=False, num_workers=2)","metadata":{"_uuid":"2bca8418-8d45-4bf5-851f-1cbbea3f151b","_cell_guid":"ece0cfaa-5281-415e-9a27-c6c5e6bb206d","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-08-08T14:36:01.838836Z","iopub.execute_input":"2023-08-08T14:36:01.839243Z","iopub.status.idle":"2023-08-08T14:36:02.003787Z","shell.execute_reply.started":"2023-08-08T14:36:01.839211Z","shell.execute_reply":"2023-08-08T14:36:02.002744Z"},"trusted":true},"execution_count":155,"outputs":[{"output_type":"display_data","data":{"text/plain":"                 record_id  train\n0      1284412112608546821  train\n1      7457695218848685981  train\n2       836236084461732921  train\n3      7829917977180135058  train\n4      5319255125658459358  train\n...                    ...    ...\n20524  8443915190215904823  train\n20525  8495643844280686935  train\n20526   856381910009426679  train\n20527  3751790308836191485  train\n20528  3682248240277515748  train\n\n[20529 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>record_id</th>\n      <th>train</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1284412112608546821</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7457695218848685981</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>836236084461732921</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7829917977180135058</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5319255125658459358</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>20524</th>\n      <td>8443915190215904823</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>20525</th>\n      <td>8495643844280686935</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>20526</th>\n      <td>856381910009426679</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>20527</th>\n      <td>3751790308836191485</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>20528</th>\n      <td>3682248240277515748</td>\n      <td>train</td>\n    </tr>\n  </tbody>\n</table>\n<p>20529 rows × 2 columns</p>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"                record_id  train\n0     3687499407028137410  valid\n1     6558861185867890815  valid\n2     7355354609194882312  valid\n3     7547747455642200110  valid\n4     5456834089979970017  valid\n...                   ...    ...\n1851   922629314296188212  valid\n1852  3319793057592206418  valid\n1853  5640456394563366318  valid\n1854  6742201885695641013  valid\n1855  8195127976521848310  valid\n\n[1856 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>record_id</th>\n      <th>train</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3687499407028137410</td>\n      <td>valid</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6558861185867890815</td>\n      <td>valid</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7355354609194882312</td>\n      <td>valid</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7547747455642200110</td>\n      <td>valid</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5456834089979970017</td>\n      <td>valid</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1851</th>\n      <td>922629314296188212</td>\n      <td>valid</td>\n    </tr>\n    <tr>\n      <th>1852</th>\n      <td>3319793057592206418</td>\n      <td>valid</td>\n    </tr>\n    <tr>\n      <th>1853</th>\n      <td>5640456394563366318</td>\n      <td>valid</td>\n    </tr>\n    <tr>\n      <th>1854</th>\n      <td>6742201885695641013</td>\n      <td>valid</td>\n    </tr>\n    <tr>\n      <th>1855</th>\n      <td>8195127976521848310</td>\n      <td>valid</td>\n    </tr>\n  </tbody>\n</table>\n<p>1856 rows × 2 columns</p>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"                 record_id  train  \\\n0      1284412112608546821  train   \n1      7457695218848685981  train   \n2       836236084461732921  train   \n3      7829917977180135058  train   \n4      5319255125658459358  train   \n...                    ...    ...   \n20524  8443915190215904823  train   \n20525  8495643844280686935  train   \n20526   856381910009426679  train   \n20527  3751790308836191485  train   \n20528  3682248240277515748  train   \n\n                                                    path  \n0      /kaggle/input/contrails-images-ash-color/contr...  \n1      /kaggle/input/contrails-images-ash-color/contr...  \n2      /kaggle/input/contrails-images-ash-color/contr...  \n3      /kaggle/input/contrails-images-ash-color/contr...  \n4      /kaggle/input/contrails-images-ash-color/contr...  \n...                                                  ...  \n20524  /kaggle/input/contrails-images-ash-color/contr...  \n20525  /kaggle/input/contrails-images-ash-color/contr...  \n20526  /kaggle/input/contrails-images-ash-color/contr...  \n20527  /kaggle/input/contrails-images-ash-color/contr...  \n20528  /kaggle/input/contrails-images-ash-color/contr...  \n\n[20529 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>record_id</th>\n      <th>train</th>\n      <th>path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1284412112608546821</td>\n      <td>train</td>\n      <td>/kaggle/input/contrails-images-ash-color/contr...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7457695218848685981</td>\n      <td>train</td>\n      <td>/kaggle/input/contrails-images-ash-color/contr...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>836236084461732921</td>\n      <td>train</td>\n      <td>/kaggle/input/contrails-images-ash-color/contr...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7829917977180135058</td>\n      <td>train</td>\n      <td>/kaggle/input/contrails-images-ash-color/contr...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5319255125658459358</td>\n      <td>train</td>\n      <td>/kaggle/input/contrails-images-ash-color/contr...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>20524</th>\n      <td>8443915190215904823</td>\n      <td>train</td>\n      <td>/kaggle/input/contrails-images-ash-color/contr...</td>\n    </tr>\n    <tr>\n      <th>20525</th>\n      <td>8495643844280686935</td>\n      <td>train</td>\n      <td>/kaggle/input/contrails-images-ash-color/contr...</td>\n    </tr>\n    <tr>\n      <th>20526</th>\n      <td>856381910009426679</td>\n      <td>train</td>\n      <td>/kaggle/input/contrails-images-ash-color/contr...</td>\n    </tr>\n    <tr>\n      <th>20527</th>\n      <td>3751790308836191485</td>\n      <td>train</td>\n      <td>/kaggle/input/contrails-images-ash-color/contr...</td>\n    </tr>\n    <tr>\n      <th>20528</th>\n      <td>3682248240277515748</td>\n      <td>train</td>\n      <td>/kaggle/input/contrails-images-ash-color/contr...</td>\n    </tr>\n  </tbody>\n</table>\n<p>20529 rows × 3 columns</p>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"                record_id  train  \\\n0     3687499407028137410  valid   \n1     6558861185867890815  valid   \n2     7355354609194882312  valid   \n3     7547747455642200110  valid   \n4     5456834089979970017  valid   \n...                   ...    ...   \n1851   922629314296188212  valid   \n1852  3319793057592206418  valid   \n1853  5640456394563366318  valid   \n1854  6742201885695641013  valid   \n1855  8195127976521848310  valid   \n\n                                                   path  \n0     /kaggle/input/contrails-images-ash-color/contr...  \n1     /kaggle/input/contrails-images-ash-color/contr...  \n2     /kaggle/input/contrails-images-ash-color/contr...  \n3     /kaggle/input/contrails-images-ash-color/contr...  \n4     /kaggle/input/contrails-images-ash-color/contr...  \n...                                                 ...  \n1851  /kaggle/input/contrails-images-ash-color/contr...  \n1852  /kaggle/input/contrails-images-ash-color/contr...  \n1853  /kaggle/input/contrails-images-ash-color/contr...  \n1854  /kaggle/input/contrails-images-ash-color/contr...  \n1855  /kaggle/input/contrails-images-ash-color/contr...  \n\n[1856 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>record_id</th>\n      <th>train</th>\n      <th>path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3687499407028137410</td>\n      <td>valid</td>\n      <td>/kaggle/input/contrails-images-ash-color/contr...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6558861185867890815</td>\n      <td>valid</td>\n      <td>/kaggle/input/contrails-images-ash-color/contr...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7355354609194882312</td>\n      <td>valid</td>\n      <td>/kaggle/input/contrails-images-ash-color/contr...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7547747455642200110</td>\n      <td>valid</td>\n      <td>/kaggle/input/contrails-images-ash-color/contr...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5456834089979970017</td>\n      <td>valid</td>\n      <td>/kaggle/input/contrails-images-ash-color/contr...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1851</th>\n      <td>922629314296188212</td>\n      <td>valid</td>\n      <td>/kaggle/input/contrails-images-ash-color/contr...</td>\n    </tr>\n    <tr>\n      <th>1852</th>\n      <td>3319793057592206418</td>\n      <td>valid</td>\n      <td>/kaggle/input/contrails-images-ash-color/contr...</td>\n    </tr>\n    <tr>\n      <th>1853</th>\n      <td>5640456394563366318</td>\n      <td>valid</td>\n      <td>/kaggle/input/contrails-images-ash-color/contr...</td>\n    </tr>\n    <tr>\n      <th>1854</th>\n      <td>6742201885695641013</td>\n      <td>valid</td>\n      <td>/kaggle/input/contrails-images-ash-color/contr...</td>\n    </tr>\n    <tr>\n      <th>1855</th>\n      <td>8195127976521848310</td>\n      <td>valid</td>\n      <td>/kaggle/input/contrails-images-ash-color/contr...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1856 rows × 3 columns</p>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(tensor([[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 5.8563e-02,\n           2.8351e-02, 0.0000e+00],\n          [2.6169e-02, 6.3438e-03, 1.7853e-02,  ..., 2.5330e-02,\n           3.0472e-02, 1.0271e-03],\n          [1.3269e-01, 1.7322e-01, 2.4255e-01,  ..., 2.1347e-02,\n           1.9592e-02, 5.0664e-06],\n          ...,\n          [4.1821e-01, 4.3457e-01, 4.5190e-01,  ..., 4.8364e-01,\n           5.1270e-01, 5.0977e-01],\n          [4.2090e-01, 4.3213e-01, 4.3335e-01,  ..., 5.0098e-01,\n           5.0977e-01, 5.1611e-01],\n          [4.7070e-01, 4.2310e-01, 3.6890e-01,  ..., 5.3027e-01,\n           5.2246e-01, 5.0928e-01]],\n \n         [[5.8008e-01, 5.0049e-01, 4.6729e-01,  ..., 6.4844e-01,\n           6.4893e-01, 6.2109e-01],\n          [6.2354e-01, 5.6445e-01, 5.1807e-01,  ..., 6.2646e-01,\n           6.3379e-01, 6.2402e-01],\n          [5.9814e-01, 5.8203e-01, 5.8691e-01,  ..., 6.2109e-01,\n           6.3281e-01, 6.2793e-01],\n          ...,\n          [3.2251e-01, 3.2202e-01, 3.4790e-01,  ..., 4.6753e-01,\n           4.5947e-01, 4.6338e-01],\n          [3.4253e-01, 3.1567e-01, 3.1494e-01,  ..., 4.5459e-01,\n           4.5093e-01, 4.5312e-01],\n          [4.1943e-01, 3.6377e-01, 3.2666e-01,  ..., 4.5605e-01,\n           4.3945e-01, 4.4482e-01]],\n \n         [[7.1484e-01, 6.5967e-01, 6.2158e-01,  ..., 7.5879e-01,\n           7.6904e-01, 7.8174e-01],\n          [6.8994e-01, 6.1865e-01, 5.3125e-01,  ..., 7.7295e-01,\n           7.7002e-01, 7.7930e-01],\n          [6.3037e-01, 5.2441e-01, 4.6509e-01,  ..., 7.7783e-01,\n           7.7539e-01, 7.7979e-01],\n          ...,\n          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n           0.0000e+00, 0.0000e+00],\n          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n           0.0000e+00, 0.0000e+00],\n          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n           0.0000e+00, 0.0000e+00]]]),\n tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]]))"},"metadata":{}}]},{"cell_type":"markdown","source":"# Training","metadata":{"_uuid":"388dfa28-ec55-47b4-861e-6dfbbb21ac01","_cell_guid":"907bc31e-3730-45d8-99ba-e9c414b66ec1","trusted":true}},{"cell_type":"code","source":"def dice_coef(y_true, y_pred, thr=0.5, epsilon=0.001):\n    \n    # If not flattened, will do 2D matrix multiplication in \"(y_true * y_pred)\" which is crazy. But all we \n    # want to do is multiply each pair of elements that are in the same position across both Tensors.\n    y_true = y_true.flatten()\n    \n    # \"(y_pred>thr)\" is basically [(i>thr?1:0) for i in y_pred]. Basically maps >thr conditional \n    # statement on each element of y_pred, so each element becomes 1 or 0.\n    y_pred = (y_pred>thr).astype(np.float32).flatten()\n    \n    # Sums the intersection of 1s ONLY (however mathematically, the entire dice coefficient will account\n    # for 0s as well, in all 4 cases of 0 0, 1 0, 0 1, 1 1, where left is ground right is pred).\n    inter = (y_true*y_pred).sum()\n    inter2 = sum([y_true[i]==y_pred[i] for i in range(len(y_pred))])\n    \n    # Sum of the sum of the set of 1s in ground truth and of the sum of the set of 1s in prediction\n    den = y_true.sum() + y_pred.sum()\n    \n    # ** Notice how we add epsilon = 0.001 to the numerator and denominator? This is to prevent 0 \n    # division error, as in the situation that the ground truth has no masks and the prediction has no \n    # masks, \"den\" would equal 0. Thus, epsilon is used to prevent 0 division error, while maintaining\n    # (relatively) proportionality between numerator and denominator.\n    dice = ((2*inter+epsilon)/(den+epsilon))\n    return dice","metadata":{"_uuid":"c422b0fe-e2b3-421b-a068-8325ba0de28f","_cell_guid":"3bd8a41b-6da9-405b-b00b-047c1726ff03","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-08-08T14:36:02.005151Z","iopub.execute_input":"2023-08-08T14:36:02.005516Z","iopub.status.idle":"2023-08-08T14:36:02.014362Z","shell.execute_reply.started":"2023-08-08T14:36:02.005490Z","shell.execute_reply":"2023-08-08T14:36:02.012840Z"},"trusted":true},"execution_count":156,"outputs":[]},{"cell_type":"code","source":"class UNet(nn.Module):\n    def __init__(self, cfg):\n        super(UNet, self).__init__()\n        \n        self.cfg = cfg\n        self.training = True\n        \n        self.model = smp.Unet(\n            encoder_name = cfg.encoder,\n            encoder_weights=cfg.weights, \n            decoder_use_batchnorm=True,\n            classes=len(cfg.classes), \n            activation=cfg.activation,\n        )\n        \n        self.loss_fn = smp.losses.DiceLoss(mode='binary')\n        \n    def forward(self, x, y):\n        '''\n        x = sample (B x C x H x W image)\n        y = label (B x H x W ground truth)\n        '''\n        \n        # pre-activation function output from CNN\n        \n        logits = self.model(x)\n        \n        loss = self.loss_fn(logits, y)\n        \n        # probabilities are given after passing logits through sigmoid function (sigmoid(x)=1/(1+e^(-x))).\n        # They can be interpreted as percentage probabilities.\n        # Note: The probabilities across different classes are not required to sum to 1, so percentage may\n        # not be the best interpretation.\n        probabilities = logits.sigmoid()\n        return {\"loss\": loss, \"probabilities\": probabilities, \"logits\": logits, \"target\": y}","metadata":{"_uuid":"a0b98051-598e-479f-8b58-3d3db33be22e","_cell_guid":"d4f42e11-2987-4f9a-a6ca-316871c7420c","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-08-08T14:36:02.016351Z","iopub.execute_input":"2023-08-08T14:36:02.017038Z","iopub.status.idle":"2023-08-08T14:36:02.029019Z","shell.execute_reply.started":"2023-08-08T14:36:02.017006Z","shell.execute_reply":"2023-08-08T14:36:02.027744Z"},"trusted":true},"execution_count":157,"outputs":[]},{"cell_type":"code","source":"def train_step(model, dataloader, optimizer, device):\n    \n    # Put model in training mode\n    model.train()\n    \n    # Array containing train loss values\n    train_losses = []\n    \n    # Progress bar\n    progress_bar = tqdm(enumerate(dataloader), total=len(dataloader), desc=\"Training\")\n    \n    for idx, (x, y) in progress_bar:\n        \n        # Move tensors to other device for efficiency\n        x = x.to(device)\n        y = y.to(device)\n        \n        torch.set_grad_enabled(True)\n        \n        output_dict = model(x, y)\n        \n        loss = output_dict[\"loss\"]\n        \n        train_losses.append(loss.item())\n        \n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        \n        if scheduler is not None:\n            scheduler.step()\n            \n    train_loss = np.sum(train_losses)\n        \n    return train_loss","metadata":{"_uuid":"80ea157d-2a96-4000-801a-364986095635","_cell_guid":"5f480912-aeb6-45b4-a036-da871d606718","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-08-08T14:36:02.031037Z","iopub.execute_input":"2023-08-08T14:36:02.031392Z","iopub.status.idle":"2023-08-08T14:36:02.045670Z","shell.execute_reply.started":"2023-08-08T14:36:02.031359Z","shell.execute_reply":"2023-08-08T14:36:02.044563Z"},"trusted":true},"execution_count":158,"outputs":[]},{"cell_type":"code","source":"def test_step(model, dataloader, device):\n    model.eval()\n    \n    torch.set_grad_enabled(False)\n    \n    val_data = defaultdict(list)\n    \n    progress_bar = tqdm(enumerate(dataloader), total=len(dataloader), desc=\"Validating\")\n    \n    for idx, (x, y) in progress_bar:\n        x = x.to(device)\n        y = y.to(device)\n        \n        output_dict = model(x, y)\n        \n        for i, j in output_dict.items():\n            val_data[i]+=[output_dict[i]]\n        \n    val_data['loss'] = torch.stack(val_data['loss'])\n    val_data['target'] = torch.cat(val_data['target'], dim=0).cpu().detach().numpy()\n    val_data['logits'] = torch.cat(val_data['logits'], dim=0).cpu().detach().numpy()\n    \n    \n    val_losses = val_data[\"loss\"].cpu().numpy()\n    val_loss = np.sum(val_losses)\n    val_dice = dice_coef(val_data['target'], val_data['logits'])\n        \n    return val_loss, val_dice","metadata":{"_uuid":"269b43a3-ad1c-4980-a866-12910f4e8d97","_cell_guid":"28a31cc1-78bc-4628-b618-603267fa270c","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-08-08T14:36:02.047699Z","iopub.execute_input":"2023-08-08T14:36:02.048121Z","iopub.status.idle":"2023-08-08T14:36:02.063362Z","shell.execute_reply.started":"2023-08-08T14:36:02.048081Z","shell.execute_reply":"2023-08-08T14:36:02.062261Z"},"trusted":true},"execution_count":159,"outputs":[]},{"cell_type":"code","source":"from tqdm.auto import tqdm","metadata":{"_uuid":"83ca7c1c-d513-43b1-8157-57a88cb0831a","_cell_guid":"6dce229f-b946-4a40-b274-dd0a73783493","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-08-08T14:36:02.066999Z","iopub.execute_input":"2023-08-08T14:36:02.067280Z","iopub.status.idle":"2023-08-08T14:36:02.075877Z","shell.execute_reply.started":"2023-08-08T14:36:02.067256Z","shell.execute_reply":"2023-08-08T14:36:02.074736Z"},"trusted":true},"execution_count":160,"outputs":[]},{"cell_type":"code","source":"def train(model, train_dl, val_dl, optimizer, epochs, device):\n    \n    train_data = {'train_loss':[], 'val_loss':[], 'val_dice':[]}\n    \n    for epoch in range(Config.num_epochs):\n        set_seed(Config.seed+epoch)\n        \n        train_loss = train_step(model, train_dl, optimizer, device)\n        \n        val_loss, val_dice = test_step(model, val_dl, device)\n        \n        train_loss = train_loss/len(train_ds)\n        val_loss = val_loss/len(valid_ds)\n        \n        train_data['train_loss'].append(train_loss)\n        train_data['val_loss'].append(val_loss)\n        train_data['val_dice'].append(val_dice)\n        \n        epoch_path = f\"epoch-{epoch}.pth\"\n        torch.save(model.state_dict(), epoch_path)\n        \n    return train_data","metadata":{"_uuid":"32f872e7-34c6-4053-a6b4-2b7c8d5257e3","_cell_guid":"8b1e74f7-8124-4690-93b9-778795bf2af9","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-08-08T14:36:02.077423Z","iopub.execute_input":"2023-08-08T14:36:02.078528Z","iopub.status.idle":"2023-08-08T14:36:02.089237Z","shell.execute_reply.started":"2023-08-08T14:36:02.078493Z","shell.execute_reply":"2023-08-08T14:36:02.088216Z"},"trusted":true},"execution_count":161,"outputs":[]},{"cell_type":"code","source":"def get_optimizer(lr, params):\n    model_optimizer = torch.optim.Adam(\n        filter(lambda parameter: parameter.requires_grad, params),\n        lr, weight_decay=0\n    )\n    return model_optimizer","metadata":{"_uuid":"bcbf8713-e6a5-475c-97bb-3320ea1abd9c","_cell_guid":"3354a933-f141-4434-bbb0-e3d02e5db222","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-08-08T14:36:02.092139Z","iopub.execute_input":"2023-08-08T14:36:02.092509Z","iopub.status.idle":"2023-08-08T14:36:02.102993Z","shell.execute_reply.started":"2023-08-08T14:36:02.092477Z","shell.execute_reply":"2023-08-08T14:36:02.101813Z"},"trusted":true},"execution_count":162,"outputs":[]},{"cell_type":"code","source":"def get_scheduler(cfg, optimizer, total_steps):\n    scheduler = get_cosine_schedule_with_warmup(\n        optimizer,\n        \n        # Note: We must do (total_steps//cfg.batch_size) because data is being passed into model in \n        # batches. I.e. every time a prediction is made, the learning rate is adjusted.\n        num_warmup_steps= cfg.warmup * (total_steps // cfg.batch_size),\n        \n        # cfg.num_epochs * (total_steps//cfg.batch_size) is the total number of predictions\n        num_training_steps= cfg.num_epochs * (total_steps // cfg.batch_size)\n    )\n    \n    return scheduler","metadata":{"_uuid":"a8dc2ed2-bbd0-49b6-b0ea-ccc8939f1705","_cell_guid":"51ec04ff-5931-4179-a408-9176254795a6","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-08-08T14:36:02.104847Z","iopub.execute_input":"2023-08-08T14:36:02.105389Z","iopub.status.idle":"2023-08-08T14:36:02.116202Z","shell.execute_reply.started":"2023-08-08T14:36:02.105356Z","shell.execute_reply":"2023-08-08T14:36:02.115225Z"},"trusted":true},"execution_count":163,"outputs":[]},{"cell_type":"code","source":"display(len(train_dl))\nfor i in train_dl:\n    display(len(i))\n    display(i[0].shape)\n    display(i[1].shape)\n    display(i[0].type)\n    display(i[1].type)\n    break\n    \ndisplay(len(valid_dl))\nfor i in valid_dl:\n    display(len(i))\n    display(i[0].shape)\n    display(i[1].shape)\n    display(i[0].type)\n    display(i[1].type)\n    break\n\n\n\nmodel = UNet(Config).to(Config.device)\n\noptimizer = get_optimizer(Config.lr, model.parameters())\nscheduler = get_scheduler(Config, optimizer, len(train_dl))\nepochs = Config.num_epochs\n\nfrom timeit import default_timer as timer\nstart_time = timer()\n\nmodel_results = train(model, train_dl, valid_dl, optimizer, epochs, Config.device)\n\nend_time = timer()\n\nprint(f'Total Training time: {end_time-start_time:.3f} seconds')","metadata":{"_uuid":"3050ad9b-b25d-414d-bc76-89dc634d7b31","_cell_guid":"42fa3608-a387-4f5f-9ac5-2dec75887368","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-08-08T14:36:02.119607Z","iopub.execute_input":"2023-08-08T14:36:02.120374Z","iopub.status.idle":"2023-08-08T16:03:08.711399Z","shell.execute_reply.started":"2023-08-08T14:36:02.120322Z","shell.execute_reply":"2023-08-08T16:03:08.709951Z"},"trusted":true},"execution_count":164,"outputs":[{"output_type":"display_data","data":{"text/plain":"642"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"2"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"torch.Size([32, 3, 256, 256])"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"torch.Size([32, 256, 256])"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<function Tensor.type>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<function Tensor.type>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"58"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"2"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"torch.Size([32, 3, 256, 256])"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"torch.Size([32, 256, 256])"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<function Tensor.type>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<function Tensor.type>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/642 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a93bffbbed774853b3d8e4f64f4baaec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/58 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f2508ec29874e65983508ee3416d780"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/642 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5668d38bbe494de9a03e923fc1e15567"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/58 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d719307446154e979db9750f8c4436b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/642 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e7f88ca472644718dcc0855e3bfe2b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/58 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"481d7307aad24d198dd211bd9ad9fc5c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/642 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8eed08c8fa447b9a8413ec60ade39b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/58 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b92c39230d1487993a7f20b7276f9d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/642 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"caceafa866484cfbae6301aab6811f50"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/58 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f520859018104dfc9955edd0007dcf39"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/642 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf17cbcffd754e35942d8bb82612a5c6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/58 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf2de11103c04f9d8f1ea2b39baa7bab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/642 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8491edf31a0f4817aaeaacfb8ab7286c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/58 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"491057db7b924850844da18feb0cc6fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/642 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ad7aa95437843299dae3fe71b53cd0e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/58 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c52b663aa3248ddbf8ca6c7642d6aa6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/642 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16e053b54d8246f595d100900a716dc5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/58 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6a1e07e473a44e28a50b6a2982da449"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/642 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07e04fc97d1a4226a0d0c93de03d6dd8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/58 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"868868149fd4433bba84716b92b1cf9a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/642 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d756c4efa714b99b732239da8dda704"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/58 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eafe0e0bb2674983903631548508307a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/642 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9395143ce6e84625834c1d1cd7101a47"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/58 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6fa6f9a17cee4dd08cf2006627190dd0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/642 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24abc29d88674835ad4057a56a859639"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/58 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ddaf5b678ef447e7925ae5e54af2658b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/642 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4667257952704d528a17f82f072b89a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/58 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e601986e09a84944be2bd39521d19b76"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/642 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e02f72144dbd4644925403416a1e8bf9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/58 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"453e1f3ea7ba43549ededede09b7af37"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/642 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87ade047356640d89d29cbc8da506bea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/58 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d72ab9b7920c430d89d910c468df6fdb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/642 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49d73e30547d418e966e54f1e5738a23"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/58 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c64017ef47ac4798929d3738035246d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/642 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a827be926fa145f2b9ebc067cb97e362"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/58 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69fa6164c58e408482ef103a314b850a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/642 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce327c7c12284946b599b0d1b3d7f1b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/58 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35b7b9a8cde345b28ec2f505faba483e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/642 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82db4093f27a45ce9f0aad0f643ffbe7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/58 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c01df0f453c64cb586b7e7e28a1abda3"}},"metadata":{}},{"name":"stdout","text":"Total Training time: 5224.133 seconds\n","output_type":"stream"}]}]}