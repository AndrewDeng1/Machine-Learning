{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Google Research - Identify Contrails to Reduce Global Warming\nThis is the notebook that uses a UNET model for inference for the \"Google Research - Identify Contrails to Reduce Global Warming\" competition on Kaggle. It ranked 765/954 with dice score 0.59090.\n\nThe dataset used for training was made by kaggler Shashwat Raman.","metadata":{}},{"cell_type":"markdown","source":"# Imports","metadata":{"_uuid":"fb4ea923-f429-4af5-8ec5-051b0c800e82","_cell_guid":"99c50a6f-be06-43a4-bc88-3d299fd560ea","trusted":true}},{"cell_type":"code","source":"from pathlib import Path\nimport os\nimport random\nimport math\nfrom collections import defaultdict\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2\n\nimport torch\nfrom torch import nn\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader\nimport albumentations as A\nimport torch.nn.functional as F\n\nfrom PIL import Image\nfrom tqdm.notebook import tqdm\nfrom transformers import get_cosine_schedule_with_warmup\nfrom tqdm.auto import tqdm","metadata":{"_uuid":"361244f9-0da0-4a71-9908-8d49ed830a70","_cell_guid":"5b27ddb8-0778-4e45-9fb2-74580754976d","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-08-08T16:20:00.202825Z","iopub.execute_input":"2023-08-08T16:20:00.203573Z","iopub.status.idle":"2023-08-08T16:20:14.181803Z","shell.execute_reply.started":"2023-08-08T16:20:00.203544Z","shell.execute_reply":"2023-08-08T16:20:14.180812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\n\nsys.path.append(\"/kaggle/input/pretrained-models-pytorch\")\nsys.path.append(\"/kaggle/input/efficientnet-pytorch\")\nsys.path.append(\"/kaggle/input/smp-github/segmentation_models.pytorch-master\")\n\nimport segmentation_models_pytorch as smp\n\nprint(f\"Segmentation Models version: {smp.__version__}\")","metadata":{"_uuid":"7a44a22f-d189-4eeb-9bca-c5488502986d","_cell_guid":"b69efec0-f5fc-4304-bf44-e4388112cc8d","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-08-08T16:20:14.183832Z","iopub.execute_input":"2023-08-08T16:20:14.186053Z","iopub.status.idle":"2023-08-08T16:20:16.637240Z","shell.execute_reply.started":"2023-08-08T16:20:14.186024Z","shell.execute_reply":"2023-08-08T16:20:16.636046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Config:\n    train = True\n    \n    num_epochs = 10\n    \n    thr = 0.02\n    \n    # No mask doesn't count as class\n    num_classes = 1\n    \n    batch_size = 32\n    seed = 42\n    \n    encoder = 'efficientnet-b0'\n    pretrained = True\n    \n    # If \"weights = 'imagenet',\" because imagenet was not imported, it must be downloaded from internet, but Kaggle notebook doesn't get internet\n    # access in submission which is why we must use \"weights = None.\"\n    weights = None\n    \n    # Class names are listed here. Class names themselves aren't actually used in the code. Only the \n    # length of this list is.\n    classes = ['contrail']\n    activation = None\n    in_chans = 3\n    \n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    \n    image_size = 256\n    warmup = 0\n    lr = 3e-4\n    \n    trained_model_state = '/kaggle/input/trained-model-state-2/epoch-19.pth'\n\n    \nclass Paths:\n    data_root = '/kaggle/input/google-research-identify-contrails-reduce-global-warming'\n    contrails = '/kaggle/input/contrails-images-ash-color/contrails/'\n    test_root = '/kaggle/input/google-research-identify-contrails-reduce-global-warming/test/'","metadata":{"_uuid":"db19ae67-a27d-45f7-b94e-e8c32f4efff5","_cell_guid":"c7c75521-3723-4fa9-9a5f-0f7001396bda","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-08-08T16:20:16.638671Z","iopub.execute_input":"2023-08-08T16:20:16.639005Z","iopub.status.idle":"2023-08-08T16:20:16.672191Z","shell.execute_reply.started":"2023-08-08T16:20:16.638980Z","shell.execute_reply":"2023-08-08T16:20:16.671012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ContrailsDataset(torch.utils.data.Dataset):\n    def __init__(self, df, train=True):\n        \n        self.df = df\n        self.trn = train\n    \n    # Handles reading from a directory under test (i.e. reads band files)\n    # Note: Only bands 11, 14, and 15 are used to create the final tensor\n    def read_record(self, directory):\n        \n        # Stores numpy arrays in a dictionary\n        record_data = {}\n        for x in [\n            \"band_11\", \n            \"band_14\", \n            \"band_15\"\n        ]:\n\n            record_data[x] = np.load(os.path.join(directory, x + \".npy\"))\n\n        # Returns dictionary mapping band name (i.e. \"band_11\") to numpy array for that band file\n        # (i.e. band_11.npy converted to numpy array)\n        return record_data\n\n    def normalize_range(self, data, bounds):\n        \"\"\"Maps data to the range [0, 1].\"\"\"\n        return (data - bounds[0]) / (bounds[1] - bounds[0])\n    \n    # This is the function responsible for taking multiple bands as input, and returning a single tensor\n    # \"False color\" = \": color in an image (such as a photograph) of an object that does not actually \n    # appear in the object but is used to enhance, contrast, or distinguish details.\"\n    def get_false_color(self, record_data):\n        _T11_BOUNDS = (243, 303)\n        _CLOUD_TOP_TDIFF_BOUNDS = (-4, 5)\n        _TDIFF_BOUNDS = (-4, 2)\n        \n        N_TIMES_BEFORE = 4\n        \n        # \"Combines\" the 'band_15', 'band_14', and 'band_11' tensors (each are 3D, H x W x Time step)\n        # Note: r, g, and b are still H x W x Time step (256 x 256 x 8)\n        r = self.normalize_range(record_data[\"band_15\"] - record_data[\"band_14\"], _TDIFF_BOUNDS)\n        g = self.normalize_range(record_data[\"band_14\"] - record_data[\"band_11\"], _CLOUD_TOP_TDIFF_BOUNDS)\n        b = self.normalize_range(record_data[\"band_14\"], _T11_BOUNDS)\n\n        # Combines 3 x (H x W x T or 256 x 256 x 8) tensors into one H x W x C x T (256 x 256 x 3 x 8)\n        false_color = np.clip(np.stack([r, g, b], axis=2), 0, 1)\n        \n        # Slice includes all dimensions 1 - 3, but only the 'N_TIMES_BEFORE'th 4th dimension element\n        img = false_color[..., N_TIMES_BEFORE]\n\n        return img\n    \n    def __getitem__(self, index):\n        row = self.df.iloc[index]\n        con_path = row.path\n        data = self.read_record(con_path)    \n\n        img = self.get_false_color(data)\n        \n        img = torch.tensor(img)\n        \n        # Changes tensor shape from H x W x C (256 x 256 x 3) to C x H x W (3 x 256 x 256)\n        img = img.permute(2, 0, 1)\n        \n        return img.float()\n    \n    def __len__(self):\n        return len(self.df)","metadata":{"_uuid":"eebdac93-867a-49fa-95d3-8da6b0f41b6a","_cell_guid":"a55034a2-b9a9-4c31-b78f-0fc49aa222cc","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-08-08T16:20:16.675368Z","iopub.execute_input":"2023-08-08T16:20:16.676251Z","iopub.status.idle":"2023-08-08T16:20:16.690903Z","shell.execute_reply.started":"2023-08-08T16:20:16.676218Z","shell.execute_reply":"2023-08-08T16:20:16.689895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_ids = os.listdir(Paths.test_root)\ntest_df = pd.DataFrame(test_ids, columns=['record_id'])\ntest_df['path'] = Paths.test_root + test_df['record_id'].astype(str)\n\ntest_ds = ContrailsDataset(test_df, False)\n\ntest_dl = DataLoader(test_ds, batch_size=Config.batch_size, num_workers=2)","metadata":{"_uuid":"e2a1ea97-28de-495f-bd84-eed949f5c295","_cell_guid":"38011c19-0f0e-427e-a6ee-1ef5eefb17bf","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-08-08T16:20:16.694585Z","iopub.execute_input":"2023-08-08T16:20:16.694908Z","iopub.status.idle":"2023-08-08T16:20:16.713153Z","shell.execute_reply.started":"2023-08-08T16:20:16.694883Z","shell.execute_reply":"2023-08-08T16:20:16.712307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class UNet(nn.Module):\n    def __init__(self, cfg):\n        super(UNet, self).__init__()\n        \n        self.cfg = cfg\n        self.training = True\n        \n        self.model = smp.Unet(\n            encoder_name=cfg.encoder, \n            encoder_weights=cfg.weights, \n            decoder_use_batchnorm=True,\n            classes=len(cfg.classes), \n            activation=cfg.activation,\n        )\n        \n        self.loss_fn = smp.losses.DiceLoss(mode='binary')\n    \n    def forward(self, imgs):\n        \n        x = imgs\n        logits = self.model(x)\n        \n        return {\"logits\": logits.sigmoid()}","metadata":{"_uuid":"a2501a88-a051-48d6-85d1-768a8e7fd94f","_cell_guid":"b04f5375-ff30-4219-a917-77553b634577","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-08-08T16:20:16.714232Z","iopub.execute_input":"2023-08-08T16:20:16.714497Z","iopub.status.idle":"2023-08-08T16:20:16.722173Z","shell.execute_reply.started":"2023-08-08T16:20:16.714474Z","shell.execute_reply":"2023-08-08T16:20:16.721176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = UNet(Config).to(Config.device)\nmodel.load_state_dict(torch.load(Config.trained_model_state, map_location=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")))","metadata":{"_uuid":"34bce483-a942-44ae-83f6-d59b34fcf68c","_cell_guid":"42a2e633-ae47-46b5-9490-c62bc4e4cf36","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-08-08T16:20:16.723546Z","iopub.execute_input":"2023-08-08T16:20:16.724490Z","iopub.status.idle":"2023-08-08T16:20:21.891765Z","shell.execute_reply.started":"2023-08-08T16:20:16.724459Z","shell.execute_reply":"2023-08-08T16:20:21.890854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval()\ntorch.set_grad_enabled(False)\n\nval_data = defaultdict(list)\n\ntest_data_loader = tqdm(enumerate(test_dl), total=len(test_dl), desc='test')\n\nfor ind, X in test_data_loader:\n    X = X.to(Config.device)\n    \n    output = model(X)\n    \n    for key, val in output.items():\n        val_data[key]+=[val]\n        \nfor key, val in output.items():\n    value = val_data[key]\n    \n    if len(value[0].shape)==0:\n        val_data[key] = torch.stack(value)\n    else:\n        val_data[key] = torch.cat(value).cpu().detach().numpy()","metadata":{"_uuid":"685febec-a422-47ba-b622-38413f30d605","_cell_guid":"45cd9758-0925-46d8-af46-b14af4f65484","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-08-08T16:20:21.893433Z","iopub.execute_input":"2023-08-08T16:20:21.893801Z","iopub.status.idle":"2023-08-08T16:20:26.681225Z","shell.execute_reply.started":"2023-08-08T16:20:21.893760Z","shell.execute_reply":"2023-08-08T16:20:26.680161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rle_encode(x, fg_val=1):\n    \"\"\"\n    Args:\n        x:  numpy array of shape (height, width), 1 - mask, 0 - background\n    Returns: run length encoding as list\n    \"\"\"\n\n    dots = np.where(\n        x.T.flatten() == fg_val)[0]  # .T sets Fortran order down-then-right\n    run_lengths = []\n    prev = -2\n    for b in dots:\n        if b > prev + 1:\n            run_lengths.extend((b + 1, 0))\n        run_lengths[-1] += 1\n        prev = b\n    return run_lengths\n\ndef list_to_string(x):\n    \"\"\"\n    Converts list to a string representation\n    Empty list returns '-'\n    \"\"\"\n    if x: # non-empty list\n        s = str(x).replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\")\n    else:\n        s = '-'\n    return s","metadata":{"_uuid":"d7d6e85e-7676-4aea-9043-172e281310d9","_cell_guid":"0dc144f0-4258-4629-82a2-86478bb95367","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-08-08T16:20:26.682755Z","iopub.execute_input":"2023-08-08T16:20:26.683119Z","iopub.status.idle":"2023-08-08T16:20:26.691050Z","shell.execute_reply.started":"2023-08-08T16:20:26.683094Z","shell.execute_reply":"2023-08-08T16:20:26.689566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv(Paths.data_root+'/sample_submission.csv', index_col='record_id')\n\ndisplay(submission)\n\nfor i, prediction in enumerate(val_data['logits']):\n    rec = test_df['record_id'][i]\n    mask = (prediction[0]>Config.thr).astype(np.float32)\n    submission.loc[int(rec), 'encoded_pixels'] = list_to_string(rle_encode(mask))\n\nsubmission.head()","metadata":{"_uuid":"43a5a71e-d4e8-4be6-bfb7-684b314cd3b8","_cell_guid":"149e17c3-a262-44f5-956e-151492dfed03","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-08-08T16:20:26.694605Z","iopub.execute_input":"2023-08-08T16:20:26.695191Z","iopub.status.idle":"2023-08-08T16:20:26.735777Z","shell.execute_reply.started":"2023-08-08T16:20:26.695160Z","shell.execute_reply":"2023-08-08T16:20:26.734824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv')","metadata":{"_uuid":"f8747950-26f2-47c5-a55a-497527c7b951","_cell_guid":"4c316ba5-b97c-4718-909a-a3112d27fe05","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-08-08T16:20:26.737753Z","iopub.execute_input":"2023-08-08T16:20:26.738405Z","iopub.status.idle":"2023-08-08T16:20:26.745411Z","shell.execute_reply.started":"2023-08-08T16:20:26.738374Z","shell.execute_reply":"2023-08-08T16:20:26.744519Z"},"trusted":true},"execution_count":null,"outputs":[]}]}